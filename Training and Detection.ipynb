{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ecb65a-69c0-4f67-997b-9bb40c3cb4d2",
   "metadata": {},
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f954bff1-74d4-4ff0-a310-150966653793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13caaada-bb61-4c0d-8ed5-30a6cec1deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet_stopsign' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d426899-7477-4cbc-80e5-296865cf057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f747b0-e7ed-4e24-ba17-a9914006b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b99500-0c25-481d-a444-ea89a54ac744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99bf3ee-8150-43e0-978c-6186ac17a74d",
   "metadata": {},
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd1f9868-46ee-4cb8-969c-cb2cc0f0c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff5006-00bd-4556-8a1a-1e22a7a71fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f0342bd-cff0-4065-abb9-3a214130afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.13.0\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-macosx_10_15_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (3.20.3)\n",
      "Requirement already satisfied: setuptools in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (1.62.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./tfod/lib/python3.11/site-packages (from tensorflow==2.13.0) (0.36.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./tfod/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./tfod/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./tfod/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./tfod/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./tfod/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./tfod/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./tfod/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./tfod/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./tfod/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./tfod/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./tfod/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./tfod/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
      "Using cached tensorflow-2.13.0-cp311-cp311-macosx_10_15_x86_64.whl (216.3 MB)\n",
      "Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.2\n",
      "    Uninstalling tensorboard-2.15.2:\n",
      "      Successfully uninstalled tensorboard-2.15.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0\n",
      "    Uninstalling tensorflow-2.15.0:\n",
      "      Successfully uninstalled tensorflow-2.15.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-models-official 2.15.0 requires tensorflow~=2.15.0, but you have tensorflow 2.13.0 which is incompatible.\n",
      "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "754fec2f-4bfc-41ac-88d5-6a66a3107504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-models-official in ./tfod/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: Cython in ./tfod/lib/python3.11/site-packages (from tf-models-official) (3.0.8)\n",
      "Requirement already satisfied: Pillow in ./tfod/lib/python3.11/site-packages (from tf-models-official) (10.2.0)\n",
      "Requirement already satisfied: gin-config in ./tfod/lib/python3.11/site-packages (from tf-models-official) (0.5.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (2.120.0)\n",
      "Requirement already satisfied: immutabledict in ./tfod/lib/python3.11/site-packages (from tf-models-official) (4.1.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (1.6.6)\n",
      "Requirement already satisfied: matplotlib in ./tfod/lib/python3.11/site-packages (from tf-models-official) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.20 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (1.24.3)\n",
      "Requirement already satisfied: oauth2client in ./tfod/lib/python3.11/site-packages (from tf-models-official) (4.1.3)\n",
      "Requirement already satisfied: opencv-python-headless in ./tfod/lib/python3.11/site-packages (from tf-models-official) (4.9.0.80)\n",
      "Requirement already satisfied: pandas>=0.22.0 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (2.2.1)\n",
      "Requirement already satisfied: psutil>=5.4.3 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (9.0.0)\n",
      "Requirement already satisfied: pycocotools in ./tfod/lib/python3.11/site-packages (from tf-models-official) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (6.0.1)\n",
      "Requirement already satisfied: sacrebleu in ./tfod/lib/python3.11/site-packages (from tf-models-official) (2.4.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in ./tfod/lib/python3.11/site-packages (from tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: seqeval in ./tfod/lib/python3.11/site-packages (from tf-models-official) (1.2.2)\n",
      "Requirement already satisfied: six in ./tfod/lib/python3.11/site-packages (from tf-models-official) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-datasets in ./tfod/lib/python3.11/site-packages (from tf-models-official) (4.9.4)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (0.16.1)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.15.0 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (2.15.0)\n",
      "Collecting tensorflow~=2.15.0 (from tf-models-official)\n",
      "  Using cached tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in ./tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in ./tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.28.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in ./tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in ./tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.17.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (4.1.1)\n",
      "Requirement already satisfied: certifi in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
      "Requirement already satisfied: requests in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (4.66.2)\n",
      "Requirement already satisfied: python-slugify in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (2.2.0)\n",
      "Requirement already satisfied: bleach in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (6.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./tfod/lib/python3.11/site-packages (from pandas>=0.22.0->tf-models-official) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./tfod/lib/python3.11/site-packages (from pandas>=0.22.0->tf-models-official) (2024.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (3.20.3)\n",
      "Requirement already satisfied: setuptools in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (65.5.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./tfod/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official) (1.62.0)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow~=2.15.0->tf-models-official)\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow~=2.15.0->tf-models-official)\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow~=2.15.0->tf-models-official)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in ./tfod/lib/python3.11/site-packages (from tensorflow-hub>=0.6.0->tf-models-official) (2.15.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in ./tfod/lib/python3.11/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./tfod/lib/python3.11/site-packages (from matplotlib->tf-models-official) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./tfod/lib/python3.11/site-packages (from matplotlib->tf-models-official) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./tfod/lib/python3.11/site-packages (from matplotlib->tf-models-official) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./tfod/lib/python3.11/site-packages (from matplotlib->tf-models-official) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./tfod/lib/python3.11/site-packages (from matplotlib->tf-models-official) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in ./tfod/lib/python3.11/site-packages (from oauth2client->tf-models-official) (0.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in ./tfod/lib/python3.11/site-packages (from oauth2client->tf-models-official) (0.3.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in ./tfod/lib/python3.11/site-packages (from oauth2client->tf-models-official) (4.9)\n",
      "Requirement already satisfied: portalocker in ./tfod/lib/python3.11/site-packages (from sacrebleu->tf-models-official) (2.8.2)\n",
      "Requirement already satisfied: regex in ./tfod/lib/python3.11/site-packages (from sacrebleu->tf-models-official) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./tfod/lib/python3.11/site-packages (from sacrebleu->tf-models-official) (0.9.0)\n",
      "Requirement already satisfied: colorama in ./tfod/lib/python3.11/site-packages (from sacrebleu->tf-models-official) (0.4.6)\n",
      "Requirement already satisfied: lxml in ./tfod/lib/python3.11/site-packages (from sacrebleu->tf-models-official) (5.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in ./tfod/lib/python3.11/site-packages (from seqeval->tf-models-official) (1.4.1.post1)\n",
      "Requirement already satisfied: click in ./tfod/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official) (8.1.7)\n",
      "Requirement already satisfied: etils>=0.9.0 in ./tfod/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (1.7.0)\n",
      "Requirement already satisfied: promise in ./tfod/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in ./tfod/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official) (1.14.0)\n",
      "Requirement already satisfied: toml in ./tfod/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official) (0.10.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./tfod/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official) (0.42.0)\n",
      "Requirement already satisfied: fsspec in ./tfod/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (2024.2.0)\n",
      "Requirement already satisfied: importlib_resources in ./tfod/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (6.1.2)\n",
      "Requirement already satisfied: zipp in ./tfod/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (3.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./tfod/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.62.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./tfod/lib/python3.11/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official) (5.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./tfod/lib/python3.11/site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./tfod/lib/python3.11/site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./tfod/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./tfod/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./tfod/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official) (3.0.1)\n",
      "Requirement already satisfied: webencodings in ./tfod/lib/python3.11/site-packages (from bleach->kaggle>=1.3.9->tf-models-official) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in ./tfod/lib/python3.11/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./tfod/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./tfod/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official) (2.1.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./tfod/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official) (3.2.2)\n",
      "Using cached tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl (239.1 MB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.13.0\n",
      "    Uninstalling tensorflow-estimator-2.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.13.0\n",
      "    Uninstalling tensorboard-2.13.0:\n",
      "      Successfully uninstalled tensorboard-2.13.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.13.0\n",
      "    Uninstalling tensorflow-2.13.0:\n",
      "      Successfully uninstalled tensorflow-2.13.0\n",
      "Successfully installed keras-2.15.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83efd9ed-3d66-43e0-956c-e53edfc55622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in ./tfod/lib/python3.11/site-packages (6.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3b78e7-a6d9-475b-aeb8-d0425b1d93ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.3 in ./tfod/lib/python3.11/site-packages (3.20.3)\n",
      "/bin/bash: protoc: command not found\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !pip install protobuf==3.20.3\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae613f6-03e6-4a6b-82df-5fbd2c51ad1b",
   "metadata": {},
   "source": [
    "### Note: If you encounter the error ModuleNotFoundError: No module named 'tensorflow.python.keras.layers.preprocessing' when running the cell below, please modify line #31 in tfod/lib/python(version)/site-packages/official/vision/image_classification/augment.py to the following: `from tensorflow.keras.preprocessing import image as image_ops`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95a5bfd8-f49e-4112-a1d8-6d965608329a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-04 13:55:59.094121: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/elexzandreia/Desktop/ObjectDetector/Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
      "    from object_detection.builders import model_builder\n",
      "ModuleNotFoundError: No module named 'object_detection'\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e163b55c-a864-4dc9-a053-26ecb6b56d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "115166d9-7838-45cc-a628-428f29bd5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall protobuf matplotlib -y\n",
    "#!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c43d168-b721-462b-bd05-51a263b63f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826584d4-a587-4caf-94fc-f65a4d37c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9dd7b7-5fa8-4e46-86a3-50af002fe02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91f80e-94e0-4c03-80ec-bada0c1aaecc",
   "metadata": {},
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf907bb-7f18-462b-b363-cbaa876cb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'StopSign', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596efd7-69de-46a6-85f7-ff32a4376aab",
   "metadata": {},
   "source": [
    "# 3. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375be2a3-d83b-40ff-98bd-cfa0278f50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "#ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "#if os.path.exists(ARCHIVE_FILES):\n",
    "#  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a9021-d3fc-45dc-97a6-faba1ac56264",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a076e1-8201-40cc-8b08-87ebde0fe0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f3821-e692-4e98-af78-678262ce6112",
   "metadata": {},
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef3115-1dcd-411f-b076-7bca4a46b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94902243-92f3-479d-9e55-653bb6103c7e",
   "metadata": {},
   "source": [
    "# 5. Update Config for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20e451-fbdb-4fc9-8af7-b5459c14b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567bd2f8-98df-40e5-8857-2045c4156344",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af1babd-e704-4ced-be90-c3b18e7b2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84130d0-cb54-4797-a03f-66b8ebb7fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa139f-1a98-4b3d-bfe3-763cb3d667c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f751a-fe5e-4b52-862c-c271177f7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b590e96-3def-4d09-b6d8-812f3e288616",
   "metadata": {},
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ec32b-7284-4a1a-abb6-17e73612c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0df0c-7baf-4587-abff-4541afcf1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a64b9-6954-46d5-a7cb-7ca0fc558bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d079f-4e27-4999-ac72-a4c8cc110cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc5bed-0965-4f4a-b8d8-33d58748a157",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684eb73e-c66d-4c25-af3f-d0f6f62ced2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a4955-c07c-45b8-a96f-f9cfe9f25388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd783e9d-0946-4b19-bbde-59829304e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562bf7d-fa05-4da5-862c-89f13a21b3af",
   "metadata": {},
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617103be-f599-4fdf-adcb-a508091c1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210d52c-29d2-4838-b36a-c164b33ac7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b88c7-9a23-4378-8d41-628d06704a9a",
   "metadata": {},
   "source": [
    "# 9. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dad1ac-125b-4203-8ab3-c2ba106d579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47a7a2-dd74-4042-a2c1-53d97b97e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d4c43-b5a7-4066-ae01-8bd9673808c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d88d9-bafc-4334-bb45-3d29952fa897",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'stop_sign_142.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea2109-1929-46ed-a664-b549f6ddf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.5,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0796b-ef54-4deb-b769-fd13b50dc8f2",
   "metadata": {},
   "source": [
    "# 10. Real Time Detections from your Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c097d-3ea8-45e2-8ff0-58fa19e782c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall opencv-python-headless -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938843d-2ed0-43f9-9aae-6fba75f3af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1) # Flip horizontally\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        # cap.release()\n",
    "        # cv2.destroyAllWindows()\n",
    "        # break\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for i in range(2):\n",
    "    cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f12161-1441-42c9-849c-305f6396317b",
   "metadata": {},
   "source": [
    "## 10. Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef150fb-3aab-49c2-9c1d-8606383684d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40f1dc-59c7-435b-92b8-6ba595789ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca04e52-9607-41f8-8009-1ae87bc186ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24425afb-270d-4a1c-b838-c13580063c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b58120-6715-47cc-8036-3f09170f7b8f",
   "metadata": {},
   "source": [
    "# 11. Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399ede1-b470-48bb-83e5-299f6ae81d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf103a9-7753-4812-b4c1-2ec8ef1652ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b07da-5128-4e9e-aa6a-1549d493a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec92502-08ba-40c9-b32f-6c3c58cdb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc487b0-c774-404f-89ec-c2441bc029c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8912666-f554-45bb-99c4-87ca1dc7c81c",
   "metadata": {},
   "source": [
    "# 12. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b11e2d-fa09-493e-945e-1b55a29fde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6901c12-f581-4f6d-ac05-b56d24759632",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb34002b-916c-497b-a9ca-12530bbc2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7da3e7-d763-41aa-9a44-bceefed0379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e87c5-bd00-41fb-898a-e766a11d59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1f486-878d-4e7d-8285-f7fac5448cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9071a-56aa-41be-b7f8-f7445e5fe197",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4d2c5-f49c-4351-9db1-2e6501383ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce530e41-28e2-4861-bfa7-8d3a5fcc9ccd",
   "metadata": {},
   "source": [
    "# 13. Zip and Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac31b875-ba54-4841-aa8b-38e207c9a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f1d16-d2df-460d-801d-8d48f16e4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
